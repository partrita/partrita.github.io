# 빈칸을 기준으로 문자열 나누기
items = "zero one two three".split()
# 쉼표를 기준으로 문자열 나누기
items = "zero,one,two,three".split()
# "."을 기준으로 문자열 나누고 unpacking
example = "cs50.gachon.edu"
subdomain, domain, tld = example.split(".")


result = []
for i in range(10):
    result.append(i)
print(result)


result = [i for i in range(10)]
print(result)


my_list = ["a", "b", "c"]
for i, j in enumerate(my_list):
    print(i, j)


list(enumerate(my_list))  # 리스트에 있는 index와 값을 unpacking 후 다시 리스트로 저장


list_a = ["a1", "a2", "a3"]
list_b = ["b1", "b2", "b3"]
for i in zip(list_a, list_b):
    print(i, end=" ")


# Lambda 사용
def f(x, y):
    return x + y


print(f(1, 4))


# python 3에는 list를 붙여야 합니다.
ex = [1, 2, 3, 4, 5]
print(list(map(lambda x: x + x, ex)))


# Reduce
from functools import reduce

print(reduce(lambda x, y: x + y, [1, 2, 3, 4, 5]))


# 위에서 배운것으로 팩토리얼을 구현해 봅니다.
def factorial(n):
    return reduce(lambda x, y: x * y, range(1, n + 1))


factorial(10)


def asterisk_test(a, *args):
    print(a, args)
    print(type(args))


asterisk_test(1, 2, 3, 4, 5, 6)


def asterisk_test(a, **kargs):
    print(a, kargs)
    print(type(kargs))


asterisk_test(1, b=2, c=3, d=4, e=5, f=6)


def asterisk_test(a, *args):
    print(a, args[0])
    print(type(args))


asterisk_test(1, (2, 3, 4, 5, 6))


def asterisk_test(a, args):
    print(a, *args)
    print(type(args))


asterisk_test(1, (2, 3, 4, 5, 6))


a, b, c = ([1, 2], [3, 4], [5, 6])
print(a, b, c)


data = ([1, 2], [3, 4], [5, 6])
print(*data)


for data in zip(*([1, 2], [3, 4], [5, 6])):
    print(sum(data))


def asterisk_test(a, b, c, d, e=0):
    print(a, b, c, d, e)


data = {"d": 1, "c": 2, "b": 3, "e": 56}
asterisk_test(10, **data)


from collections import Counter

c = Counter()  # a new, empty counter
c = Counter("gallahad")  # a new counter from an iterable
print(c)


u = [2, 2]
v = [2, 3]
z = [3, 5]

result = [t for t in zip(u, v, z)]
print(result)


matrix_a = [[3, 6], [4, 5]]
matrix_b = [[5, 8], [6, 7]]
result = [[sum(row) for row in zip(*t)] for t in zip(matrix_a, matrix_b)]

print(result)


matrix_a = [[1, 2, 3], [4, 5, 6]]
result = [[element for element in t] for t in zip(*matrix_a)]

[t for t in zip(*matrix_a)]
print(result)


matrix_a = [[1, 1, 2], [2, 1, 1]]
matrix_b = [[1, 1], [2, 1], [1, 3]]
result = [
    [sum(a * b for a, b in zip(row_a, column_b)) for column_b in zip(*matrix_b)]
    for row_a in matrix_a
]
print(result)


# Problem #1 - vector_size_check
def vector_size_check(*vector_variables):
    return all(len(vector_variables[0]) == len(i) for i in vector_variables)


# 실행결과
print(vector_size_check([1, 2, 3], [2, 3, 4], [5, 6, 7]))  # Expected value: True
print(vector_size_check([1, 3, 4], [4], [6, 7]))  # Expected value: False


# Problem #2 - vector_addition
def vector_addition(*vector_variables):
    return [sum(i) for i in zip(*vector_variables)]


# 실행결과
print(vector_addition([1, 3], [2, 4], [6, 7]))  # Expected value: [9, 14]
print(vector_addition([1, 5], [10, 4], [4, 7]))  # Expected value: [15, 16]


# Problem #3 - vector_subtraction
def vector_subtraction(*vector_variables):
    if vector_size_check(*vector_variables) is False:
        raise ArithmeticError
    return [i[0] * 2 - sum(i) for i in zip(*vector_variables)]


# 실행결과
print(vector_subtraction([1, 3], [2, 4]))  # Expected value: [-1, -1]
print(vector_subtraction([1, 5], [10, 4], [4, 7]))  # Expected value: [-13, -6]


# Problem #4 - scalar_vector_product (one line code available)
def scalar_vector_product(alpha, vector_variable):
    return [alpha * i for i in vector_variable]


# 실행결과
print(scalar_vector_product(5, [1, 2, 3]))  # Expected value: [5, 10, 15]
print(scalar_vector_product(3, [2, 2]))  # Expected value: [6, 6]
print(scalar_vector_product(4, [1]))  # Expected value: [4]


import numpy as np

# array의 생성
test_matrix = np.array([[1, 2, 3, 4], [1, 2, 5, 8]])
test_matrix


test_matrix.shape


np.array(test_matrix).reshape(
    8,
)


np.array(test_matrix).flatten()


test_matrix[:, 1]  # 2번째 column 부터


test_matrix[1, :]  # 2번째 row 부터


a = np.array([[1, 2, 3]])
b = np.array([[2, 3, 4]])
np.concatenate((a, b), axis=0)


np.concatenate((a, b), axis=1)


test_matrix.dtype


# float 형으로 변경해줍니다.
test_matrix_float = test_matrix.astype(float)
test_matrix_float.dtype


import pandas as pd

data_url = "https://www.shanelynn.ie/wp-content/uploads/2015/06/phone_data.csv"
df = pd.read_csv(data_url, index_col=0)
df.tail()


df[:3]  # 위에서 3번째까지의 데이터 선택


df[["duration", "network"]][:3]


import dateutil

df["date"] = df["date"].apply(dateutil.parser.parse, dayfirst=True)
df.head()


df.groupby("month")["duration"].sum()


df.pivot_table(["duration"], index=df.month, aggfunc="sum")


raw_data = {
    "first_name": ["Jason", np.nan, "Tina", "Jake", "Amy"],
    "last_name": ["Miller", np.nan, "Ali", "Milner", "Cooze"],
    "age": [42, np.nan, 36, 24, 73],
    "sex": ["m", np.nan, "f", "m", "f"],
    "preTestScore": [4, np.nan, np.nan, 2, 3],
    "postTestScore": [25, np.nan, np.nan, 62, 70],
}
df = pd.DataFrame(
    raw_data,
    columns=["first_name", "last_name", "age", "sex", "preTestScore", "postTestScore"],
)
df


# NA 값이 하나라도 있는 데이터는 지우기
df_no_missing = df.dropna(axis=0, thresh=6)
df_no_missing


# 모든 값이 NA인 데이터 지우기
df_cleaned = df.dropna(how="all")
df_cleaned


# NA값을 0으로 바꾸기
df.fillna(0)


# 성별 컬럼을 one-hot-encoding 해보겠습니다.
pd.concat([df, pd.get_dummies(df["sex"], prefix="sex")], axis=1)


from sklearn import preprocessing

df = df.fillna(0)  # NA값을 제거하기 위해
minmax_scaler = preprocessing.MinMaxScaler().fit(df[["preTestScore", "postTestScore"]])
df[["preTestScore", "postTestScore"]] = minmax_scaler.transform(
    df[["preTestScore", "postTestScore"]]
)
df


import numpy as np

test_matrix = np.array([[1, 2, 3, 4], [1, 2, 5, 8]])


def change_shape_of_ndarray(X, n_row):
    if n_row == 1:
        return X.flatten()
    else:
        return X.reshape(n_row, -1)


change_shape_of_ndarray(test_matrix, 1)


test_matrix = np.array([1, 2, 3, 4])


def save_ndarray(X, filename="test.npy"):
    with open(filename, "wb") as f:
        np.save(X, f)


def boolean_index(X, condition):
    condition = eval(str("X") + condition)
    return np.where(condition)


boolean_index(test_matrix, ">2")


test_matrix = np.array([1, 2, 3, 4])


def find_nearest_value(X, target_value):
    return X[np.argmin(np.abs(X - target_value))]


find_nearest_value(test_matrix, 0.1)


test_matrix = np.array([1, 2, 3, 4])


def get_n_largest_values(X, n):
    return X[np.argsort(X[::-1])[:n]]


get_n_largest_values(test_matrix, 2)


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
get_ipython().run_line_magic("matplotlib", " inline")

#  LOAD DATASET - simple variable
df_train = pd.read_csv("./data/normal_eq_train.csv")
df_test = pd.read_csv("./data/normal_eq_test.csv")
# df_test.head()
X_train = df_train["x"].values.reshape(-1, 1)
X_test = df_test["x"].values.reshape(-1, 1)
y_train = df_train["y"].values
y_test = df_test["y"].values
df_train.tail()


plt.scatter(X_train, y_train, alpha=0.3)


from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score

lr = linear_model.LinearRegression(normalize=False)  # false 이유?
lr.fit(X_train, y_train)


y_pred = lr.predict(X_test)

# The coefficients
print("Coefficients: {:02.3f} ".format(lr.coef_[0]))
# The mean squared error
print("Mean squared error: {:02.3f}".format(mean_squared_error(y_test, y_pred)))
# Explained variance score: 1 is perfect prediction
print("Variance score: {:02.3f}".format(r2_score(y_test, y_pred)))


# Plot outputs
plt.scatter(X_test, y_test, alpha=0.3)
plt.plot(X_test, y_pred, color="red")
plt.show()


# LOAD DATASET
df = pd.read_csv("./data/SwedishMotorInsurance.csv")
df.tail()


# X = number of claims
# Y = total payment for all the claims in thousands of Swedish Kronor
raw_X = df["Claims"].values.reshape(-1, 1)
y = df["Payment"].values / 10000
plt.plot(raw_X, y, "o", alpha=0.5)


raw_X[:5], y[:5]


np.ones((len(raw_X), 1))[:3]


X = np.concatenate((np.ones((len(raw_X), 1)), raw_X), axis=1)
X[:5]


w = np.random.normal((0, 4))  # 초기 weight값을 임의로 정해줍니다.
w


y_predict = np.dot(X, w)
plt.plot(raw_X, y, "o", alpha=0.5)
plt.plot(raw_X, y_predict)


# HYPOTHESIS AND COST FUNCTION
def hypothesis_function(X, theta):
    return X.dot(theta)


def cost_function(h, y):
    return (1 / (2 * len(y))) * np.sum((h - y) ** 2)


h = hypothesis_function(X, w)
cost_function(h, y)


# GRADIENT DESCENT
def gradient_descent(X, y, w, alpha, iterations):
    theta = w
    m = len(y)
    theta_list = [theta.tolist()]
    cost = cost_function(hypothesis_function(X, theta), y)
    cost_list = [cost]
    for i in range(iterations):
        t0 = theta[0] - (alpha / m) * np.sum(np.dot(X, theta) - y)
        t1 = theta[1] - (alpha / m) * np.sum((np.dot(X, theta) - y) * X[:, 1])
        theta = np.array([t0, t1])
        if i % 10 == 0:
            theta_list.append(theta.tolist())
            cost = cost_function(hypothesis_function(X, theta), y)
            cost_list.append(cost)
    return theta, theta_list, cost_list


# DO Linear regression with GD
iterations = 70  # 학습횟수
alpha = 0.00001  # 학습률

theta, theta_list, cost_list = gradient_descent(X, y, w, alpha, iterations)
cost = cost_function(hypothesis_function(X, theta), y)

print("theta:", theta)
print("cost:", cost_function(hypothesis_function(X, theta), y))


theta_list[:10]


theta_list = np.array(theta_list)
cost_list


y_predict_step = np.dot(X, theta_list.transpose())
y_predict_step
plt.plot(raw_X, y, "o", alpha=0.3)
for i in range(0, len(cost_list)):
    plt.plot(raw_X, y_predict_step[:, i], label="Line %d" % i)

plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)
plt.show()


plt.plot(range(len(cost_list)), cost_list)


from sklearn.datasets import load_boston
import matplotlib.pyplot as plt
import numpy as np
import random

get_ipython().run_line_magic("matplotlib", " inline")


def gen_data(numPoints, bias, variance):
    x = np.zeros(shape=(numPoints, 3))
    y = np.zeros(shape=numPoints)
    # basically a straight line
    for i in range(0, numPoints):
        # bias feature
        x[i][0] = random.uniform(0, 1) * variance + i
        x[i][1] = random.uniform(0, 1) * variance + i
        x[i][2] = 1
        # our target variable
        y[i] = (i + bias) + random.uniform(0, 1) * variance + 500
    return x, y


# gen 100 points with a bias of 25 and 10 variance as a bit of noise
x, y = gen_data(100, 25, 10)

plt.plot(x[:, 0:1], "ro")
plt.plot(y, "bo")

plt.show()



fig = plt.figure()
ax = fig.add_subplot(111, projection="3d")
ax.scatter(x[:, 0], x[:, 1], y)

ax.set_xlabel("X0 Label")
ax.set_ylabel("X1 Label")
ax.set_zlabel("Y Label")

plt.show()


def compute_cost(x, y, theta):
    """
    Comput cost for linear regression
    """
    # Number of training samples
    m = y.size
    predictions = x.dot(theta)
    sqErrors = predictions - y

    J = (1.0 / (2 * m)) * sqErrors.T.dot(sqErrors)
    return J


def minimize_gradient(x, y, theta, iterations=100000, alpha=0.01):
    m = y.size
    cost_history = []
    theta_history = []

    for _ in range(iterations):
        predictions = x.dot(theta)

        for i in range(theta.size):
            partial_marginal = x[:, i]
            errors_xi = (predictions - y) * partial_marginal
            theta[i] = theta[i] - alpha * (1.0 / m) * errors_xi.sum()

        if _ % 1000 == 0:
            theta_history.append(theta)
            cost_history.append(compute_cost(x, y, theta))

    return theta, np.array(cost_history), np.array(theta_history)


theta_initial = np.ones(3)
theta, cost_history, theta_history = minimize_gradient(
    x, y, theta_initial, 300000, 0.0001
)
print("theta", theta)


from sklearn import linear_model

regr = linear_model.LinearRegression()
regr.fit(x[:, :2], y)

# # The coefficients
print("Coefficients: ", regr.coef_)
print("intercept: ", regr.intercept_)


print(np.dot(theta, x[10]))
print(regr.predict(x[10, :2].reshape(1, 2)))


import matplotlib.pyplot as plt
import numpy as np

fig = plt.figure()
ax = fig.add_subplot(111, projection="3d")
ax.scatter3D(theta_history[:, 0], theta_history[:, 1], cost_history, zdir="z")
plt.show()


plt.plot(cost_history)
plt.show()


# Mean Absolute Error(MAE)
from sklearn.metrics import median_absolute_error

y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]

median_absolute_error(y_true, y_pred)


# Root Mean Squared Error(RMSE)
from sklearn.metrics import mean_squared_error

y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]

mean_squared_error(y_true, y_pred)


# R squared
from sklearn.metrics import r2_score

y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]

r2_score(y_true, y_pred)


from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
import warnings

warnings.filterwarnings("ignore")

# 데이터 불러오기
boston = load_boston()
df = pd.DataFrame(boston.data, columns=boston.feature_names)
X = df.values
y = boston.target

# feature scailing
from sklearn.preprocessing import StandardScaler

std_scaler = StandardScaler()
std_scaler.fit(X)
X_scaled = std_scaler.transform(X)

# 데이터 나누기
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42
)

# SGDRegression 하기
from sklearn.linear_model import SGDRegressor

lr_SGD = SGDRegressor()
lr_SGD.fit(X_train, y_train)

y_hat = lr_SGD.predict(X_test)
y_true = y_test

# 평가하기
from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_hat, y_true)
rmse = np.sqrt((((y_hat - y_true) ** 2).sum() / len(y_true)))
# 시각화하기
plt.scatter(y_true, y_hat, s=10)
plt.xlabel("Prices: $Y_i$")
plt.ylabel("Predicted prices: $\hat{Y}_i$")
plt.title("Prices vs Predicted prices: $Y_i$ vs $\hat{Y}_i$")


# train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)


# Linear Regression with Ridge & Lasso regression
from sklearn.linear_model import Lasso, Ridge

ridge = Ridge(fit_intercept=True, alpha=0.5)
ridge.fit(X_train, y_train)
# lasso = Lasso(fit_intercept=True, alpha=0.5)
y_hat = ridge.predict(X_test)
y_true = y_test
mse = mean_squared_error(y_hat, y_true)
rmse = np.sqrt((((y_hat - y_true) ** 2).sum() / len(y_true)))
# rmse, mse
plt.scatter(y_true, y_hat, s=10)
plt.xlabel("Prices: $Y_i$")
plt.ylabel("Predicted prices: $\hat{Y}_i$")
plt.title("Prices vs Predicted prices: $Y_i$ vs $\hat{Y}_i$")


from sklearn.model_selection import KFold

print("Ridge Regression")
print("alpha\t RMSE_train\t RMSE_10cv\n")
alpha = np.linspace(0.01, 100, 10)
t_rmse = np.array([])
cv_rmse = np.array([])

for a in alpha:
    ridge = Ridge(fit_intercept=True, alpha=a)

    # computing the RMSE on training data
    ridge.fit(X_train, y_train)
    p = ridge.predict(X_test)
    err = p - y_test
    total_error = np.dot(err, err)
    rmse_train = np.sqrt(total_error / len(p))

    # computing RMSE using 10-fold cross validation
    kf = KFold(10)
    xval_err = 0
    for train, test in kf.split(X):
        ridge.fit(X[train], y[train])
        p = ridge.predict(X[test])
        err = p - y[test]
        xval_err += np.dot(err, err)
    rmse_10cv = np.sqrt(xval_err / len(X))

    t_rmse = np.append(t_rmse, [rmse_train])
    cv_rmse = np.append(cv_rmse, [rmse_10cv])
    print("{:.3f}\t {:.4f}\t\t {:.4f}".format(a, rmse_train, rmse_10cv))


plt.plot(alpha, t_rmse, label="RMSE-Train")
plt.plot(alpha, cv_rmse, label="RMSE_XVal")
plt.legend(("RMSE-Train", "RMSE_XVal"))
plt.ylabel("RMSE")
plt.xlabel("Alpha")


a = 0.3
for name, met in [
    ("lasso", Lasso(fit_intercept=True, alpha=a)),
    ("ridge", Ridge(fit_intercept=True, alpha=a)),
]:
    met.fit(X_train, y_train)
    # p = np.array([met.predict(xi) for xi in x])
    p = met.predict(X_test)
    e = p - y_test
    total_error = np.dot(e, e)
    rmse_train = np.sqrt(total_error / len(p))

    kf = KFold(10)
    err = 0
    for train, test in kf.split(X):
        met.fit(X[train], y[train])
        p = met.predict(X[test])
        e = p - y[test]
        err += np.dot(e, e)

    rmse_10cv = np.sqrt(err / len(X))
    print("Method: %s" % name)
    print("RMSE on training: %.4f" % rmse_train)
    print("RMSE on 10-fold CV: %.4f" % rmse_10cv)


from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
import warnings
warnings.filterwarnings("ignore")

# Create matrix and vectors
X = [[0.44, 0.68], [0.99, 0.23]]
y = [109.85, 155.72]
X_test = [[0.49, 0.18]]

# PolynomialFeatures (prepreprocessing)
poly = PolynomialFeatures(degree=2)
X_ = poly.fit_transform(X)
X_test_ = poly.fit_transform(X_test)

# Instantiate
lg = LinearRegression()

# Fit
lg.fit(X_, y)

# Obtain coefficients
lg.coef_


# Predict
lg.predict(X_test_)


from sklearn import datasets

boston = datasets.load_boston()
X = boston.data
y = boston.target


from sklearn.model_selection import KFold

kf = KFold(n_splits=5, shuffle=True)
for train_index, test_index in kf.split(X):
    print("TRAIN - ", len(train_index))
    print("TEST - ", len(test_index))


from sklearn.model_selection import cross_val_score
import numpy as np

lasso_regressor = Lasso(warm_start=False)
ridge_regressor = Ridge()

lasso_scores = cross_val_score(
    lasso_regressor, X, y, cv=10, scoring="neg_mean_squared_error"
)
ridge_scores = cross_val_score(
    ridge_regressor, X, y, cv=10, scoring="neg_mean_squared_error"
)
np.mean(lasso_scores), np.mean(ridge_scores)


from sklearn.model_selection import LeaveOneOut

test = [1, 2, 3, 4]
loo = LeaveOneOut()
for train, test in loo.split(test):
    print("%s %s" % (train, test))


import pandas as pd
import numpy as np

df = pd.read_csv("./data/binary.csv")
# rename the 'rank' column because there is also a DataFrame method called 'rank'
df.columns = ["admit", "gre", "gpa", "prestige"]
df.tail()


import matplotlib.pyplot as plt

get_ipython().run_line_magic("matplotlib", " inline")
df.hist()


from sklearn import preprocessing  # Min-Max Standardzation

y_data = df["admit"].values.reshape(-1, 1)
x_data = df.ix[:, 1:].values

min_max_scaler = preprocessing.MinMaxScaler()
x_data = min_max_scaler.fit_transform(x_data)

x_data[:5]


from sklearn import linear_model, datasets

X_train, X_test, y_train, y_test = train_test_split(
    x_data, y_data, test_size=0.3, random_state=42
)

logreg = linear_model.LogisticRegression(fit_intercept=True)
logreg.fit(X_train, y_train.ravel())

y_pred = logreg.predict(X_test)
y_true = y_test

from sklearn.metrics import accuracy_score

accuracy_score(y_true, y_pred)
